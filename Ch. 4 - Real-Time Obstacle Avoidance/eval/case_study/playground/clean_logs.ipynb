{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "624067bf-a8aa-41ca-9c31-ad809175cb18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import statistics\n",
    "\n",
    "repo = '<path to data repo>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75882e61-4f7e-43d1-a610-e9e681b9ce44",
   "metadata": {},
   "source": [
    "# Model checking plan data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "925ed9c0-5e3f-418d-b295-cc49428ff324",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_plan_data(run):\n",
    "    data = []\n",
    "    file = open(repo+'/{}/autoctrl.txt'.format(run), 'r')\n",
    "    \n",
    "    for line in file:\n",
    "        if line.split(':')[0] == 'ACCEPT':\n",
    "            data.append(line.split(':')[-1].strip())\n",
    "        elif line.split(':')[0] == 'PATH':\n",
    "            data.append(line.split(':')[-1].strip())\n",
    "        elif line.split(':')[0] == 'PLAN':\n",
    "            data.append(line.split(':')[-1].strip())\n",
    "        elif line.strip()[-2:] == 'ms':\n",
    "            d = line.split('!')[1].strip()[:-2]\n",
    "            data.append(float(d))\n",
    "            \n",
    "    file.close()\n",
    "    \n",
    "    if len(data) == 0:\n",
    "        data = [None] * 8\n",
    "    \n",
    "    if len(data) == 4:\n",
    "        data += [None] * 4\n",
    "\n",
    "    data_ = []\n",
    "    for x in data:\n",
    "        if x == '' or str(x)[0] == '*':\n",
    "            data_.append(None)\n",
    "        else:\n",
    "            data_.append(x)\n",
    "\n",
    "    res = []\n",
    "    a = []\n",
    "    count = 0\n",
    "    for i in range(len(data_)):\n",
    "        a.append(data_[i])\n",
    "        if count == 3:\n",
    "            res.append(a)\n",
    "            a = []\n",
    "            count = 0\n",
    "        else:\n",
    "            count += 1\n",
    "\n",
    "    for item in res:\n",
    "        if item[1] != None:\n",
    "            nsteps = len(item[1].split(' '))\n",
    "            item.append(nsteps)\n",
    "        else:\n",
    "            item.append(0)\n",
    "\n",
    "    cols = ['accept', 'path', 'plan', 'latency', 'steps']\n",
    "    df = pd.DataFrame(data=res, columns=cols)\n",
    "    return df\n",
    "\n",
    "def add_plan_data(n_runs):\n",
    "    count = 0\n",
    "    for run in os.listdir(repo):\n",
    "        if run[0] == '0':\n",
    "            df = extract_plan_data(run)\n",
    "            df.to_csv(repo+'/{}/{}plan.csv'.format(run, run))\n",
    "            count += 1\n",
    "      \n",
    "    try:\n",
    "        assert count == n_runs\n",
    "    except AssertionError:\n",
    "        print('FAILED: count = {}'.format(count))\n",
    "    \n",
    "add_plan_data(n_runs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7575676-10e6-49b6-ae74-1d86b11e5eb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model checking resource usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d3df9bc5-3d23-4efa-92a8-87e50dd69a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_stack_data(data):\n",
    "    result = []\n",
    "    \n",
    "    for item in data:\n",
    "        if item[:3] != 'SET':\n",
    "            result.append(item.strip())\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    result = result[2:-2]\n",
    "    # get stack size data here\n",
    "    result = [int(x[-1]) for x in result]\n",
    "            \n",
    "    return result\n",
    "    \n",
    "def _extract_set_data(data):\n",
    "    result = []\n",
    "    \n",
    "    for item in reversed(data[:-5]):\n",
    "        if item[:3] != 'SET':\n",
    "            try:\n",
    "                result.append(int(item.strip()))\n",
    "            except ValueError:\n",
    "                pass\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    return result\n",
    "    \n",
    "def extract_performance_data(run):\n",
    "    perf = []\n",
    "    \n",
    "    for file in os.listdir(repo+'\\{}'.format(run)):\n",
    "        if file[:3] == 'dfs':\n",
    "            with open(repo+'\\{}\\{}'.format(run, file)) as infile:\n",
    "                perf.append(infile.readlines())\n",
    "         \n",
    "    set_data = []\n",
    "    stack_data = []\n",
    "    \n",
    "    for data in perf:\n",
    "        stack_data.append(max(_extract_stack_data(data)))\n",
    "        set_data.append(max(_extract_set_data(data)))\n",
    "    \n",
    "    return stack_data, set_data\n",
    "\n",
    "def add_performance_to_run_data(n_runs):\n",
    "    count = 0\n",
    "    for run in os.listdir(repo):    \n",
    "        if run[0] == '0':\n",
    "            stack_data, set_data = extract_performance_data(run)\n",
    "    \n",
    "            df = pd.DataFrame()\n",
    "            df['stack_data'] = stack_data\n",
    "            df['set_data'] = set_data\n",
    "            df['state_size'] = 4\n",
    "            df['n_states'] = 15\n",
    "            df['adj_list_compile'] = 184\n",
    "            df['stack_compile'] = 12\n",
    "            df['set_compile'] = 24\n",
    "            df.to_csv(repo+'/{}/{}model_check.csv'.format(run, run))\n",
    "            count += 1\n",
    "            \n",
    "    try:\n",
    "        assert count == n_runs\n",
    "    except AssertionError:\n",
    "        print('FAILED: count = {}'.format(count))\n",
    "\n",
    "add_performance_to_run_data(n_runs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124f0215-731d-44b2-bc2b-3e6739869c22",
   "metadata": {},
   "source": [
    "# Process resource usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "72e69058-185e-4039-a558-3621d9b2001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_process_memory(run):\n",
    "    swap = []\n",
    "    physical = []\n",
    "    process = []\n",
    "    \n",
    "    file = open(repo+'/{}/usage.txt'.format(run), 'r')\n",
    "    \n",
    "    for line in file:\n",
    "        if line.split(':')[0] == 'MiB Mem ':\n",
    "            physical.append(line.split(':')[-1].strip())\n",
    "        elif line.split(':')[0] == 'MiB Swap':\n",
    "            swap.append(line.split(':')[-1].strip())\n",
    "        elif line.strip()[-8:] == 'autoctrl':\n",
    "            process.append(line)\n",
    "\n",
    "    file.close()\n",
    "\n",
    "    # physical data\n",
    "    physical_ = []\n",
    "    physical = [x.split(',') for x in physical]\n",
    "    for row in physical:\n",
    "        physical_.append([float(x.strip()[:4]) for x in row])\n",
    "\n",
    "    # swap data\n",
    "    swap_ = []\n",
    "    swap = [x.split(',') for x in swap]\n",
    "    for row in swap:   \n",
    "        swap_.append([x.strip() for x in row])\n",
    "\n",
    "    swap__ = []\n",
    "    for row in swap_:\n",
    "        swap__.append([float(x.split()[0]) for x in row])\n",
    "\n",
    "    # process data\n",
    "    process_ = []\n",
    "    for row in process:   \n",
    "        process_.append(row.strip()[9:-8].strip().split(' '))\n",
    "\n",
    "    process__ = []\n",
    "    for row in process_:\n",
    "        process__.append([x for x in row if x != ''])\n",
    "\n",
    "    for i in range(len(process__)):    \n",
    "        for j in range(len(process__[i])):\n",
    "            if ':' in process__[i][j]:\n",
    "                process__[i][j] = process__[i][j][-5:]\n",
    "                \n",
    "            try:\n",
    "                process__[i][j] = float(process__[i][j])\n",
    "            except ValueError:\n",
    "                pass\n",
    "                \n",
    "    phy_cols = ['mem_total', 'mem_free', 'mem_used', 'cache']\n",
    "    phy = pd.DataFrame(data=physical_, columns=phy_cols)\n",
    "\n",
    "    swp_cols = ['swap_total', 'swap_free', 'swap_used']\n",
    "    swp = pd.DataFrame(data=swap__, columns=swp_cols)\n",
    "\n",
    "    proc_cols = ['pr', 'ni', 'virt', 'res', 'shr', 'status', \n",
    "                 'cpu_perc', 'mem_perc', 'cpu_time']\n",
    "    proc = pd.DataFrame(data=process__, columns=proc_cols)\n",
    "\n",
    "    df = pd.merge(proc, phy, how='inner', left_index=True, right_index=True)\n",
    "    df = pd.merge(df, swp, how='inner', left_index=True, right_index=True)\n",
    "    df['process_uptime'] = 0.001 * df.index\n",
    "    df = df[df.mem_perc > 0]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_process_to_run_data(n_runs):\n",
    "    count = 0\n",
    "    for run in os.listdir(repo):    \n",
    "        df = _extract_process_memory(run)\n",
    "        df.to_csv(repo+'/{}/{}usage.csv'.format(run, run))\n",
    "\n",
    "        count += 1\n",
    "    try:\n",
    "        assert count == n_runs\n",
    "    except AssertionError:\n",
    "        print('FAILED: count = {}'.format(count))\n",
    "\n",
    "add_process_to_run_data(n_runs=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
